{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98313fc4-17cb-4902-a3d1-ab2932c5acec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Year_Birth</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Dt_Customer</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>...</th>\n",
       "      <th>AcceptedCmp4</th>\n",
       "      <th>AcceptedCmp5</th>\n",
       "      <th>AcceptedCmp1</th>\n",
       "      <th>AcceptedCmp2</th>\n",
       "      <th>Complain</th>\n",
       "      <th>Z_CostContact</th>\n",
       "      <th>Z_Revenue</th>\n",
       "      <th>Response</th>\n",
       "      <th>Age</th>\n",
       "      <th>Recency_Months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5524</td>\n",
       "      <td>1957</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>58138.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-09-04</td>\n",
       "      <td>58</td>\n",
       "      <td>635</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2174</td>\n",
       "      <td>1954</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>46344.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-03-08</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4141</td>\n",
       "      <td>1965</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Together</td>\n",
       "      <td>71613.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-08-21</td>\n",
       "      <td>26</td>\n",
       "      <td>426</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6182</td>\n",
       "      <td>1984</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Together</td>\n",
       "      <td>26646.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-02-10</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5324</td>\n",
       "      <td>1981</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Married</td>\n",
       "      <td>58293.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-01-19</td>\n",
       "      <td>94</td>\n",
       "      <td>173</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  Year_Birth   Education Marital_Status   Income  Kidhome  Teenhome  \\\n",
       "0  5524        1957  Graduation         Single  58138.0        0         0   \n",
       "1  2174        1954  Graduation         Single  46344.0        1         1   \n",
       "2  4141        1965  Graduation       Together  71613.0        0         0   \n",
       "3  6182        1984  Graduation       Together  26646.0        1         0   \n",
       "4  5324        1981         PhD        Married  58293.0        1         0   \n",
       "\n",
       "  Dt_Customer  Recency  MntWines  ...  AcceptedCmp4  AcceptedCmp5  \\\n",
       "0  2012-09-04       58       635  ...             0             0   \n",
       "1  2014-03-08       38        11  ...             0             0   \n",
       "2  2013-08-21       26       426  ...             0             0   \n",
       "3  2014-02-10       26        11  ...             0             0   \n",
       "4  2014-01-19       94       173  ...             0             0   \n",
       "\n",
       "   AcceptedCmp1  AcceptedCmp2  Complain  Z_CostContact  Z_Revenue  Response  \\\n",
       "0             0             0         0              3         11         1   \n",
       "1             0             0         0              3         11         0   \n",
       "2             0             0         0              3         11         0   \n",
       "3             0             0         0              3         11         0   \n",
       "4             0             0         0              3         11         0   \n",
       "\n",
       "   Age  Recency_Months  \n",
       "0   69             162  \n",
       "1   72             144  \n",
       "2   61             151  \n",
       "3   42             145  \n",
       "4   45             146  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import/load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv('Data/cleaned_marketing_campaign.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57db6b18-7ccc-46ae-a22e-c2262ead720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "# Convert categorical features to 'category'\n",
    "df['Education'] = df['Education'].astype('category')\n",
    "df['Marital_Status'] = df['Marital_Status'].astype('category')\n",
    "\n",
    "# Create dummy variables\n",
    "df = pd.get_dummies(df, columns=['Education', 'Marital_Status'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d04eabd6-833f-47e9-b906-e549829c6481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "num_cols = ['Income', 'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts',\n",
    "            'MntSweetProducts', 'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases',\n",
    "            'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth', 'Age', 'Recency']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c381311-8d38-4a96-ae59-e3d154def079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 1789 rows\n",
      "Testing set size: 448 rows\n"
     ]
    }
   ],
   "source": [
    "# Test/Train\n",
    "X = df.drop(columns=['Response', 'ID', 'Dt_Customer'])\n",
    "y = df['Response']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} rows\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f965a374-e2aa-41dd-a753-347def4f409b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression (Balanced) Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.83      0.88       376\n",
      "           1       0.45      0.75      0.57        72\n",
      "\n",
      "    accuracy                           0.81       448\n",
      "   macro avg       0.70      0.79      0.72       448\n",
      "weighted avg       0.87      0.81      0.83       448\n",
      "\n",
      "Accuracy: 0.8147321428571429\n"
     ]
    }
   ],
   "source": [
    "# Model 1: Logistic Regression (balanced)\n",
    "logreg = LogisticRegression(class_weight='balanced', max_iter=5000, random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression (Balanced) Performance:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ac0aa35-adb1-4a70-bb34-f367b0168fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93       376\n",
      "           1       0.74      0.36      0.49        72\n",
      "\n",
      "    accuracy                           0.88       448\n",
      "   macro avg       0.82      0.67      0.71       448\n",
      "weighted avg       0.87      0.88      0.86       448\n",
      "\n",
      "Accuracy: 0.8772321428571429\n"
     ]
    }
   ],
   "source": [
    "# Model 2: Random Forest (baseline)\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Performance:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fad4ab8-70b5-40b5-a62a-25cccd72cd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93       376\n",
      "           1       0.74      0.43      0.54        72\n",
      "\n",
      "    accuracy                           0.88       448\n",
      "   macro avg       0.82      0.70      0.74       448\n",
      "weighted avg       0.87      0.88      0.87       448\n",
      "\n",
      "Accuracy: 0.8839285714285714\n"
     ]
    }
   ],
   "source": [
    "# Model 3: Gradient Boosting\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "\n",
    "print(\"Gradient Boosting Performance:\")\n",
    "print(classification_report(y_test, y_pred_gb))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec304fb4-8b79-4145-a31a-c6bc5ef873d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8147\n",
      "Random Forest Accuracy: 0.8772\n",
      "Gradient Boosting Accuracy: 0.8839\n"
     ]
    }
   ],
   "source": [
    "# Model Comparison: Accuracy\n",
    "logreg_acc = accuracy_score(y_test, y_pred)\n",
    "rf_acc = accuracy_score(y_test, y_pred_rf)\n",
    "gb_acc = accuracy_score(y_test, y_pred_gb)\n",
    "\n",
    "print(f\"Logistic Regression Accuracy: {logreg_acc:.4f}\")\n",
    "print(f\"Random Forest Accuracy: {rf_acc:.4f}\")\n",
    "print(f\"Gradient Boosting Accuracy: {gb_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fe1d21a-7a1d-4087-a6ee-a656affd2a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest (Tuned) Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93       376\n",
      "           1       0.74      0.32      0.45        72\n",
      "\n",
      "    accuracy                           0.87       448\n",
      "   macro avg       0.81      0.65      0.69       448\n",
      "weighted avg       0.86      0.87      0.85       448\n",
      "\n",
      "Accuracy: 0.8727678571428571\n",
      "Best parameters found: {'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Best CV score: 0.884847346759933\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Hyperparameter Tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42),\n",
    "                           param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred_best_rf = best_rf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest (Tuned) Performance:\")\n",
    "print(classification_report(y_test, y_pred_best_rf))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_best_rf))\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "print(\"Best CV score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fdef15d-7f6b-4cdc-82df-438e86da7f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Class 1 Recall</th>\n",
       "      <th>Class 1 F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression (Balanced)</td>\n",
       "      <td>0.814732</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.565445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.877232</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.485981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.883929</td>\n",
       "      <td>0.430556</td>\n",
       "      <td>0.543860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest (Tuned)</td>\n",
       "      <td>0.872768</td>\n",
       "      <td>0.319444</td>\n",
       "      <td>0.446602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model  Accuracy  Class 1 Recall  Class 1 F1\n",
       "0  Logistic Regression (Balanced)  0.814732        0.750000    0.565445\n",
       "1                   Random Forest  0.877232        0.361111    0.485981\n",
       "2               Gradient Boosting  0.883929        0.430556    0.543860\n",
       "3           Random Forest (Tuned)  0.872768        0.319444    0.446602"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Comparison\n",
    "from sklearn.metrics import recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Predictions\n",
    "y_pred_logreg = logreg.predict(X_test)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "y_pred_best_rf = best_rf.predict(X_test)\n",
    "\n",
    "# Comparison DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': [\n",
    "        'Logistic Regression (Balanced)', \n",
    "        'Random Forest', \n",
    "        'Gradient Boosting', \n",
    "        'Random Forest (Tuned)'\n",
    "    ],\n",
    "    'Accuracy': [\n",
    "        accuracy_score(y_test, y_pred_logreg),\n",
    "        accuracy_score(y_test, y_pred_rf),\n",
    "        accuracy_score(y_test, y_pred_gb),\n",
    "        accuracy_score(y_test, y_pred_best_rf)\n",
    "    ],\n",
    "    'Class 1 Recall': [\n",
    "        recall_score(y_test, y_pred_logreg, pos_label=1),\n",
    "        recall_score(y_test, y_pred_rf, pos_label=1),\n",
    "        recall_score(y_test, y_pred_gb, pos_label=1),\n",
    "        recall_score(y_test, y_pred_best_rf, pos_label=1)\n",
    "    ],\n",
    "    'Class 1 F1': [\n",
    "        f1_score(y_test, y_pred_logreg, pos_label=1),\n",
    "        f1_score(y_test, y_pred_rf, pos_label=1),\n",
    "        f1_score(y_test, y_pred_gb, pos_label=1),\n",
    "        f1_score(y_test, y_pred_best_rf, pos_label=1)\n",
    "    ]\n",
    "})\n",
    "\n",
    "comparison_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1110b360-d4ed-4a68-8024-38943ae9dab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Final Model Selection\n",
    "\n",
    "I evaluated four models on the development dataset:  \n",
    "\n",
    "1. Logistic Regression (class-weighted, balanced)  \n",
    "2. Random Forest (baseline)  \n",
    "3. Gradient Boosting  \n",
    "4. Random Forest (hyperparameter-tuned)  \n",
    "\n",
    "Here’s a quick summary of the results:\n",
    "\n",
    "| Model | Accuracy | Class 1 Recall | Class 1 F1 |\n",
    "|-------|---------|----------------|------------|\n",
    "| Logistic Regression (Balanced) | 0.815 | 0.75 | 0.57 |\n",
    "| Random Forest | 0.877 | 0.36 | 0.49 |\n",
    "| Gradient Boosting | 0.884 | 0.43 | 0.54 |\n",
    "| Random Forest (Tuned) | 0.873 | 0.32 | 0.45 |\n",
    "\n",
    "A few things stand out:  \n",
    "\n",
    "- Gradient Boosting and Random Forest have the highest overall accuracy, but they miss a lot of positive responders.  \n",
    "- Logistic Regression with class weighting catches most of the responders, giving the highest recall and F1 for the positive class.  \n",
    "- Even after tuning, Random Forest didn’t improve on finding responders.\n",
    "\n",
    "Because only about 15% of people responded, the main goal is to identify as many responders as possible. For this reason, I'm choosing class-weighted Logistic Regression as the final model.  \n",
    "\n",
    "Note: The best Random Forest parameters were `{'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 100}`, but even with tuning it still missed too many responders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2333ce-f947-4c3c-84bd-8bf8c8071656",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
